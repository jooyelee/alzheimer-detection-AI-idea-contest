{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jooye_test.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jooyelee/alzheimer-detection-AI-idea-contest/blob/main/jooye_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpuBTR0gVYHo"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRX9wvK6Uman"
      },
      "source": [
        "import numpy as np \r\n",
        "from tqdm import tqdm\r\n",
        "import cv2\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import itertools\r\n",
        "import imutils\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\r\n",
        "\r\n",
        "import plotly.graph_objs as go\r\n",
        "from plotly.offline import init_notebook_mode, iplot\r\n",
        "from plotly import tools\r\n",
        "\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\r\n",
        "from keras import layers\r\n",
        "from keras.models import Model, Sequential\r\n",
        "from keras.optimizers import Adam, RMSprop\r\n",
        "from keras.callbacks import EarlyStopping\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RnhzgCml22a"
      },
      "source": [
        "\r\n",
        "init_notebook_mode(connected=True)\r\n",
        "RANDOM_SEED = 123\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "%matplotlib inline   \r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import seaborn as sns  \r\n",
        "\r\n",
        "\r\n",
        "#from sklearn.preprocessing import MinMaxScaler\r\n",
        "#from tensorflow.keras.layers import Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQMAjI_8V3vX"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/sample2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2at9lZqsW7OB"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVq974Woup9J"
      },
      "source": [
        "data.isnull().sum(1) # row 단위로 결측값 구하기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1GLtX-eXBNs"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzACt5sQ75_O"
      },
      "source": [
        "data.columns.get_loc(\"CERAD_J1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0E798GR8CrF"
      },
      "source": [
        "data.columns.get_loc(\"CDR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqATEOyg8ShM"
      },
      "source": [
        "data.columns.get_loc(\"MMSE 총점\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gclimirUWfhh"
      },
      "source": [
        "data.columns.get_loc(\"Left-Lateral-Ventricle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECrfvOUtsjQV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP9BXl0n5xvq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDMlQkCc5yOu"
      },
      "source": [
        "# 데이터 분할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w8pksNrDzOn"
      },
      "source": [
        "cdr_df = data.iloc[:,33:36]\r\n",
        "cdr1 = data.iloc[:,4]\r\n",
        "\r\n",
        "cerad_col = data.columns[19:33]\r\n",
        "cerad_df = data.iloc[:,19:33]\r\n",
        "\r\n",
        "mri_col = data.columns[72:]\r\n",
        "mri_df = data.iloc[:,72:]\r\n",
        "\r\n",
        "cerad_cdr = pd.merge(cerad_df,cdr_df,left_index=True, right_index=True, how='left')\r\n",
        "\r\n",
        "cerad_df=cerad_df.drop(columns=[\"CERAD_total1\",\"CERAD_total2\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMGBPJG99PM3"
      },
      "source": [
        "def draw_histograms(df, variables, n_rows):\r\n",
        "    fig=plt.figure(figsize=(15,30))\r\n",
        "   \r\n",
        "    for i, var_name in enumerate(variables):\r\n",
        "        ax=fig.add_subplot(n_rows,2,i+1)\r\n",
        "        df[var_name].hist(bins=10,ax=ax)\r\n",
        "        ax.set_title(var_name)\r\n",
        "    fig.tight_layout()  # Improves appearance a bit.\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "draw_histograms(cerad_df, cerad_df.columns,15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk-UYuVe8Xy5"
      },
      "source": [
        "cerad_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALPMZejK-3mG"
      },
      "source": [
        "\r\n",
        "plt.figure(figsize=(15,15))\r\n",
        "sns.heatmap(data = cerad_df.corr(), annot=True, fmt = '.2f', linewidths=.5, cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHfFpKN_ECCd"
      },
      "source": [
        "plt.figure(figsize=(15,15))\r\n",
        "sns.heatmap(data = cerad_cdr.corr(), annot=True, fmt = '.2f', linewidths=.5, cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFt276tvPcM6"
      },
      "source": [
        "no_cerad_cdr = cerad_cdr.dropna()\r\n",
        "nona = cerad_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-c041IZPzU5"
      },
      "source": [
        "nona.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EmD184048LQ"
      },
      "source": [
        "# PCA & K MEANS CLUSTERING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ujdZgduQLjc"
      },
      "source": [
        "from sklearn.preprocessing import scale, normalize\r\n",
        "scale = scale(nona)\r\n",
        "normal = normalize(nona)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfFbbLBQNGS-"
      },
      "source": [
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "pca = PCA()\r\n",
        "\r\n",
        "scaled_pca = pca.fit_transform(scale)\r\n",
        "\r\n",
        "print(\"pca.explained_variance_ratio_:\",pca.explained_variance_ratio_)\r\n",
        "\r\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\r\n",
        "d = np.argmax(cumsum >= 0.80) + 1\r\n",
        "print('선택할 차원 수 :', d)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztO7dfQ6TN1y"
      },
      "source": [
        "pca = PCA()\r\n",
        "normal_pca = pca.fit_transform(normal)\r\n",
        "\r\n",
        "print(\"pca.explained_variance_ratio_:\",pca.explained_variance_ratio_)\r\n",
        "\r\n",
        "cumsum = np.cumsum(pca.explained_variance_ratio_)\r\n",
        "d = np.argmax(cumsum >= 0.95) + 1\r\n",
        "print('선택할 차원 수 :', d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qllubmIyTZT1"
      },
      "source": [
        "normal_pca_df = pd.DataFrame(normal_pca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAGNze7wTZWo"
      },
      "source": [
        "normal_pca_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqD2blCMJ9D7"
      },
      "source": [
        "normal_pca_cdr_df  = pd.merge(normal_pca_df,cdr_df.dropna(),left_index=True, right_index=True, how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BnOvogZJ9Mz"
      },
      "source": [
        "normal_pca_cdr_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcGbuFw5KbgA"
      },
      "source": [
        "nona_normal_pca_cdr_df = normal_pca_cdr_df.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFvOpRZV-jq_"
      },
      "source": [
        "fig = plt.figure()\r\n",
        "ax = fig.gca(projection=\"3d\")\r\n",
        "\r\n",
        "x,y,z = nona_normal_pca_cdr_df[0], nona_normal_pca_cdr_df[1],nona_normal_pca_cdr_df[2]\r\n",
        "\r\n",
        "ax.scatter(x,y,z)\r\n",
        "\r\n",
        "ax.set_xlabel(\"pca 1\")\r\n",
        "ax.set_ylabel(\"pca 2\")\r\n",
        "ax.set_zlabel(\"pca 3\")\r\n",
        "plt.suptitle(\"k mean clustering(pca)\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STkNIsjyULGf"
      },
      "source": [
        "plt.scatter(nona_normal_pca_cdr_df[0], nona_normal_pca_cdr_df[1], alpha=.3)\r\n",
        "plt.xlabel('PCA 1')\r\n",
        "plt.ylabel('PCA 2')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyynzV2CUSth"
      },
      "source": [
        "from sklearn.cluster import KMeans\r\n",
        "inertias = []\r\n",
        "\r\n",
        "# Creating 10 K-Mean models while varying the number of clusters (k)\r\n",
        "for k in range(1,10):\r\n",
        "    model = KMeans(n_clusters=k)\r\n",
        "    \r\n",
        "    # Fit model to samples\r\n",
        "    model.fit(nona_normal_pca_cdr_df.iloc[:,:3])\r\n",
        "    \r\n",
        "    # Append the inertia to the list of inertias\r\n",
        "    inertias.append(model.inertia_)\r\n",
        "    \r\n",
        "plt.plot(range(1,10), inertias, '-p', color='gold')\r\n",
        "plt.xlabel('number of clusters, k')\r\n",
        "plt.ylabel('inertia')\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhhIitRjUpqR"
      },
      "source": [
        "model = KMeans(n_clusters=2)\r\n",
        "model.fit(normal_pca_df.iloc[:,:3])\r\n",
        "\r\n",
        "labels = model.predict(nona_normal_pca_cdr_df.iloc[:,:3])\r\n",
        "\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.gca(projection=\"3d\")\r\n",
        "\r\n",
        "x,y,z = nona_normal_pca_cdr_df[0], nona_normal_pca_cdr_df[1],nona_normal_pca_cdr_df[2]\r\n",
        "\r\n",
        "ax.scatter(x,y,z, c=labels)\r\n",
        "\r\n",
        "ax.set_xlabel(\"pca 1\")\r\n",
        "ax.set_ylabel(\"pca 2\")\r\n",
        "ax.set_zlabel(\"pca 3\")\r\n",
        "plt.suptitle(\"k mean clustering(pca)\")\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOxphgxNLwzx"
      },
      "source": [
        "\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.gca(projection=\"3d\")\r\n",
        "\r\n",
        "x,y,z = nona_normal_pca_cdr_df[0], nona_normal_pca_cdr_df[1],nona_normal_pca_cdr_df[2]\r\n",
        "cdr = nona_normal_pca_cdr_df[\"CDR\"]\r\n",
        "cdr2 = cdr2 = [ 0 if i>0.2  else 1 for i in cdr]\r\n",
        "\r\n",
        "ax.scatter(x,y,z, c=cdr2)\r\n",
        "\r\n",
        "ax.set_xlabel(\"pca 1\")\r\n",
        "\r\n",
        "ax.set_ylabel(\"pca 2\")\r\n",
        "ax.set_zlabel(\"pca 3\")\r\n",
        "plt.suptitle(\"k mean clustering(pca)\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfQepFiMMin7"
      },
      "source": [
        "cdr = nona_normal_pca_cdr_df[\"CDR\"]\r\n",
        "cdr2 = [ 0 if i>0.2  else 1 for i in cdr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moRNr_Dmf03S"
      },
      "source": [
        "위 결과로 k means clustering은 cdr를 정상 비정상으로 판별을 하여 그리 좋은 정확도를 가지지 않음\r\n",
        "\r\n",
        "다른 방법을 활용해야됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W897S_Mr42kp"
      },
      "source": [
        "# RANDOM FOREST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Oamm2NXPzL"
      },
      "source": [
        "## mci"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbHmm5cFQZ34"
      },
      "source": [
        "### 0123"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-MxOCcg2w2j"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# age&f/m/education\r\n",
        "\r\n",
        "age_fm_edu = data.iloc[:,1:4]\r\n",
        "y_0123 = data.iloc[:,4]\r\n",
        "xx = pd.merge(cerad_df,age_fm_edu,left_index=True, right_index=True, how='left')\r\n",
        "\r\n",
        "all = pd.merge(xx,y_0123,left_index=True, right_index=True, how='left').dropna()\r\n",
        "\r\n",
        "def randomforest0123(data,n):\r\n",
        "  normal_normal = []\r\n",
        "  dem_normal = []\r\n",
        "  for i in range(n):\r\n",
        "# test train 분리\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\r\n",
        "\r\n",
        "    rf0123 = RandomForestClassifier(oob_score=True)\r\n",
        "    rf0123.fit(X_train,y_train)\r\n",
        "\r\n",
        "    predicted = rf0123.predict(X_test)\r\n",
        "    accuracy = accuracy_score(y_test, predicted)\r\n",
        "    cm = confusion_matrix(y_test, predicted, labels = [0,1,2,3])\r\n",
        "    #print(cm)\r\n",
        "\r\n",
        "    nn = cm[0][0]/cm.sum(axis=1)[0] ; \r\n",
        "    normal_normal.append(nn)\r\n",
        "    #print(\"정상 - 정상:\",nn)\r\n",
        "   \r\n",
        "\r\n",
        "    dn = (cm.sum(axis=0)[0]-cm[0][0])/(cm.sum()-cm.sum(axis=1)[0]) ; dem_normal.append(dn)\r\n",
        "    #print(\"치매 - 정상:\",dn)\r\n",
        "\r\n",
        "    #print('\\nClassification Report\\n')\r\n",
        "    #print(classification_report(y_test, predicted))\r\n",
        "  #print(type(normal_normal))\r\n",
        "  #print(type(dem_normal))\r\n",
        "  df = pd.DataFrame(dem_normal,columns=[\"치매 -> 정상\"])\r\n",
        "  df[\"정상 to 정상\"]=normal_normal\r\n",
        "  #print(df)\r\n",
        "  return df\r\n",
        "cm0123 = randomforest0123(all,100)\r\n",
        "cm0123.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLu3GI8mQVgl"
      },
      "source": [
        "### 0&1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-n8dZCARpsF"
      },
      "source": [
        "# 치매는 다 1 로 바꾸기\r\n",
        "all[\"y0123\"] = all.iloc[:,-1]\r\n",
        "y01 = []\r\n",
        "for i in all[\"y0123\"]:\r\n",
        "  if i == 0:\r\n",
        "    y01.append(i)\r\n",
        "  else:\r\n",
        "    y01.append(1)\r\n",
        "\r\n",
        "def randomforest01(x,y,n=100):\r\n",
        "  normal_normal = []\r\n",
        "  dem_normal = []\r\n",
        "  for i in range(n):\r\n",
        "# test train 분리\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3)\r\n",
        "\r\n",
        "    rf0123 = RandomForestClassifier(oob_score=True)\r\n",
        "    rf0123.fit(X_train,y_train)\r\n",
        "\r\n",
        "    predicted = rf0123.predict(X_test)\r\n",
        "    accuracy = accuracy_score(y_test, predicted)\r\n",
        "    cm = confusion_matrix(y_test, predicted, labels = [0,1])\r\n",
        "    nn = cm[0][0]/cm.sum(axis=1)[0] ; \r\n",
        "    normal_normal.append(nn)\r\n",
        "    dn = cm[1][0] / cm.sum(axis=1)[1] \r\n",
        "    dem_normal.append(dn)\r\n",
        "  df = pd.DataFrame(dem_normal,columns=[\"치매 -> 정상\"])\r\n",
        "  df[\"정상 to 정상\"]=normal_normal\r\n",
        "  return df\r\n",
        "  \r\n",
        "cm01 = randomforest01(all.iloc[:,:-2],y01)\r\n",
        "cm01.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-REJ3UeXSea"
      },
      "source": [
        "## cdr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEQEdGrdXUAv"
      },
      "source": [
        "### 0, 0.5, 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZomXhkRFXKBe"
      },
      "source": [
        "xx = pd.merge(cerad_df,age_fm_edu,left_index=True, right_index=True, how='left')\r\n",
        "yy = cdr_df.iloc[:,-3]*2\r\n",
        "all_cdr = pd.merge(xx,yy,left_index=True, right_index=True, how='left').dropna()\r\n",
        "all_cdr[\"CDR\"]=all_cdr.CDR.astype(int)\r\n",
        "\r\n",
        "def randomforest0051(data,n=10):\r\n",
        "  normal_normal = []\r\n",
        "  dem_normal = []\r\n",
        "  for i in range(n):\r\n",
        "# test train 분리\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.3)\r\n",
        "\r\n",
        "    rf0123 = RandomForestClassifier()\r\n",
        "    rf0123.fit(X_train,y_train)\r\n",
        "\r\n",
        "    predicted = rf0123.predict(X_test)\r\n",
        "    accuracy = accuracy_score(y_test, predicted)\r\n",
        "    cm = confusion_matrix(y_test, predicted, labels = [0, 0.5, 1])\r\n",
        "    #print(cm)\r\n",
        "    nn = cm[0][0]/cm.sum(axis=1)[0] \r\n",
        "    normal_normal.append(nn)\r\n",
        "    print(\"정상 - 정상:\",nn)\r\n",
        "    dn = (cm.sum(axis=0)[0]-cm[0][0])/(cm.sum()-cm.sum(axis=1)[0]) ; dem_normal.append(dn)\r\n",
        "    print(\"치매 - 정상:\",dn)\r\n",
        "\r\n",
        "  df = pd.DataFrame(dem_normal,columns=[\"치매 -> 정상\"])\r\n",
        "  df[\"정상 to 정상\"]=normal_normal\r\n",
        "  #print(df)\r\n",
        "  return df\r\n",
        "\r\n",
        "cm0051 = randomforest0051(all_cdr)\r\n",
        "cm0051.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjhPlKyd-NgY"
      },
      "source": [
        "#### confusion matrix 를 보면 0->0 정상: 정상은 다 갔고, 치매 --> 치매가 아님 이 1개 그외는 좋음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ue3VDxLNfyv"
      },
      "source": [
        "fig = plt.figure()\r\n",
        "ax = fig.gca(projection=\"3d\")\r\n",
        "\r\n",
        "x,y,z = nona_normal_pca_cdr_df[0], nona_normal_pca_cdr_df[1],nona_normal_pca_cdr_df[2]\r\n",
        "\r\n",
        "ax.scatter(x,y,z, c=nona_normal_pca_cdr_df.iloc[:,-1])\r\n",
        "\r\n",
        "ax.set_xlabel(\"pca 1\")\r\n",
        "\r\n",
        "ax.set_ylabel(\"pca 2\")\r\n",
        "ax.set_zlabel(\"pca 3\")\r\n",
        "plt.suptitle(\"k mean clustering(pca)\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgaL_3S3BhKh"
      },
      "source": [
        "cdr_df.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-pl8u71BhOd"
      },
      "source": [
        "data.tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwCHAgdXkNuP"
      },
      "source": [
        "mri_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyBH8F6xkguY"
      },
      "source": [
        "%matplotlib inline   \r\n",
        "import matplotlib.pyplot as plt \r\n",
        "import seaborn as sns  \r\n",
        "\r\n",
        "plt.figure(figsize=(50,50))\r\n",
        "sns.heatmap(data = mri_df.corr(), annot=False, linewidths=.5, cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzhcGif5Un5X"
      },
      "source": [
        "mri_cdr = pd.merge(mri_df,cdr_df,left_index=True, right_index=True, how='left')\r\n",
        "mri_cdr.head()\r\n",
        "plt.figure(figsize=(50,50))\r\n",
        "sns.heatmap(data = mri_cdr.corr(), annot=False, linewidths=.5, cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evYpbf3GiJzf"
      },
      "source": [
        "# MRI\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7c_A5alxXDO"
      },
      "source": [
        "total = pd.merge(mri_df,y_0123,left_index=True, right_index=True, how='left').dropna()\r\n",
        "total.iloc[:,-1] = total.iloc[:,-1].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCYWLAhrlRSi"
      },
      "source": [
        "## 차원축소 해보자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILqKDmLTnxV4"
      },
      "source": [
        "### kernal pca fuction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNBPviKTnwoh"
      },
      "source": [
        "from scipy.spatial.distance import pdist, squareform\r\n",
        "from scipy import exp\r\n",
        "from scipy.linalg import eigh\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def rbf_kernel_pca(X, gamma, n_components):\r\n",
        "    # MxN 차원의 데이터셋에서 샘플 간의 유클리디안 거리의 제곱을 계산합니다.\r\n",
        "    sq_dists = pdist(X, 'sqeuclidean')\r\n",
        "\r\n",
        "    # 샘플 간의 거리를 정방 대칭 행렬로 변환합니다.\r\n",
        "    mat_sq_dists = squareform(sq_dists)\r\n",
        "\r\n",
        "    # 커널 행렬을 계산합니다.\r\n",
        "    K = exp(-gamma * mat_sq_dists)\r\n",
        "\r\n",
        "    # 커널 행렬을 중앙에 맞춥니다.\r\n",
        "    N = K.shape[0]\r\n",
        "    one_n = np.ones((N, N)) / N\r\n",
        "    K = K - one_n.dot(K) - K.dot(one_n) + one_n.dot(K).dot(one_n)\r\n",
        "\r\n",
        "    # 중앙에 맞춰진 커널 행렬의 고윳값과 고유벡터를 구합니다.\r\n",
        "    # scipy.linalg.eigh 함수는 오름차순으로 반환합니다.\r\n",
        "    eigvals, eigvecs = eigh(K)\r\n",
        "    eigvals, eigvecs = eigvals[::-1], eigvecs[:, ::-1]\r\n",
        "\r\n",
        "    # 최상위 k 개의 고유벡터를 선택합니다(결과값은 투영된 샘플입니다).\r\n",
        "    X_pc = np.column_stack([eigvecs[:, i]\r\n",
        "                            for i in range(n_components)])\r\n",
        "\r\n",
        "    return X_pc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3yTX7j5k5ZW"
      },
      "source": [
        "x = total.iloc[:,:-1]\r\n",
        "X_kpca = rbf_kernel_pca(x,gamma=10,n_components=3)\r\n",
        "print(X_kpca)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pqNYmQmpdV9"
      },
      "source": [
        "from sklearn.decomposition import KernelPCA\r\n",
        "x = total.iloc[:,:-1]\r\n",
        "y = total.iloc[:,-1]\r\n",
        "\r\n",
        "kpca = KernelPCA(n_components = 3, kernel=\"poly\",gamma=10)\r\n",
        "X_kpca = kpca.fit_transform(x)\r\n",
        "\r\n",
        "kpca = pd.DataFrame(X_kpca)\r\n",
        "kpca[\"y\"] = y\r\n",
        "kpca.columns=[\"pca1\",\"pca2\",\"pca3\",\"y\"]\r\n",
        "kpca = kpca.dropna()\r\n",
        "kpca.head(3)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VKmVEmo4ul9"
      },
      "source": [
        "kpca.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-JiObt14mOp"
      },
      "source": [
        "kpca[\"y\"] = kpca[\"y\"].astype(int)\r\n",
        "d0 = kpca.query(\" y == 0 \")\r\n",
        "d1 = kpca.query(\" y == 1 \")\r\n",
        "d2 = kpca.query(\" y == 2 \")\r\n",
        "d3 = kpca.query(\" y == 3 \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6BrizUW1VZj"
      },
      "source": [
        "kpca.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2i8MsqEL1PH"
      },
      "source": [
        "# 데이터 생성: smote etc.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzafh_80JH67"
      },
      "source": [
        "total_mri = mri_df\r\n",
        "total_mri[\"y\"]=y_0123\r\n",
        "total_mri = total_mri.dropna()\r\n",
        "total_mri.y = total_mri.y.astype(int)\r\n",
        "\r\n",
        "total_mri.y.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjxzB44uJH-f"
      },
      "source": [
        "d0 = total_mri.query(\" y == 0 \")\r\n",
        "d1 = total_mri.query(\" y == 1 \")\r\n",
        "d2 = total_mri.query(\" y == 2 \")\r\n",
        "d3 = total_mri.query(\" y == 3 \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS4tJ7AcJH2Z"
      },
      "source": [
        "plt.figure(figsize=(50,50))\r\n",
        "sns.heatmap(data = total_mri.corr(), annot=False, linewidths=.5, cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VjgUZ_0Xlsr"
      },
      "source": [
        "mri_cor = pd.DataFrame(total_mri.corr())\r\n",
        "cor = mri_cor[\"y\"][:-1]\r\n",
        "\r\n",
        "plus4 = mri_cor.query(\"(y >= 0.4)\")\r\n",
        "minus4 =  mri_cor.query(\"(y <= -0.4)\")\r\n",
        "zero =  mri_cor.query(\"(y<0.1) & (y> -0.1)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JhUUspeZsj_"
      },
      "source": [
        "plus4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gl11LFIZyPH"
      },
      "source": [
        "minus4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTM5OEjzaLnb"
      },
      "source": [
        "zero"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amkvnd0HNQ0f"
      },
      "source": [
        "### smote: multi class classifier\r\n",
        "\r\n",
        "https://machinelearningmastery.com/multi-class-imbalanced-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQM-JmknPcER"
      },
      "source": [
        "# load and summarize the dataset\r\n",
        "from collections import Counter\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "\r\n",
        "x = total_mri.iloc[:,:-1]\r\n",
        "y = total_mri.iloc[:,-1]\r\n",
        "\r\n",
        "# label encode the target variable\r\n",
        "y = LabelEncoder().fit_transform(y)\r\n",
        "# summarize distribution\r\n",
        "counter = Counter(y)\r\n",
        "for k,v in counter.items():\r\n",
        "\tper = v / len(y) * 100\r\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\r\n",
        "# plot the distribution\r\n",
        "plt.bar(counter.keys(), counter.values())\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4eGb9GjoHjV"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\r\n",
        "\r\n",
        "x = total_mri.iloc[:,:-1]\r\n",
        "y = total_mri.iloc[:,-1]\r\n",
        "\r\n",
        "# transform the dataset & k_neighboors = 4 한 이유는 젤 작은 클라스 갯수가 5라서 k가 6 이상이면 못씀\r\n",
        "oversample = SMOTE(k_neighbors=4)\r\n",
        "x_, y_ = oversample.fit_resample(x, y)\r\n",
        "# summarize distribution\r\n",
        "counter = Counter(y_)\r\n",
        "for k,v in counter.items():\r\n",
        "\tper = v / len(y) * 100\r\n",
        "\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\r\n",
        "# plot the distribution\r\n",
        "plt.bar(counter.keys(), counter.values())\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwsgPAKeoHnZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCxn5ysL00h0"
      },
      "source": [
        "# anova 로 뽑은 파라미터로 random forest 해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAKyHWHN06ev"
      },
      "source": [
        "colname = [\r\n",
        " 'CERAD_J1',\r\n",
        " 'CERAD_J2',\r\n",
        " 'CERAD_J3',\r\n",
        " 'CERAD_J4',\r\n",
        " 'CERAD_J6',\r\n",
        " 'CERAD_J7',\r\n",
        " 'CERAD_J8',\r\n",
        " 'CERAD_J9A',\r\n",
        " 'CERAD_J9B',\r\n",
        " 'CERAD_J가1',\r\n",
        " 'CERAD_J가2',\r\n",
        " 'CDR',\r\n",
        " 'Left-Inf-Lat-Vent',\r\n",
        " 'Right-Inf-Lat-Vent',\r\n",
        " 'lh_superiorparietal_volume',\r\n",
        " 'rh_fusiform_volume',\r\n",
        " 'rh_temporalpole_volume',\r\n",
        " 'lh_caudalmiddlefrontal_thickness',\r\n",
        " 'lh_fusiform_thickness',\r\n",
        " 'lh_inferiortemporal_thickness',\r\n",
        " 'lh_isthmuscingulate_thickness',\r\n",
        " 'lh_lingual_thickness',\r\n",
        " 'lh_middletemporal_thickness',\r\n",
        " 'lh_parsopercularis_thickness',\r\n",
        " 'lh_parstriangularis_thickness',\r\n",
        " 'lh_postcentral_thickness',\r\n",
        " 'lh_posteriorcingulate_thickness',\r\n",
        " 'lh_precentral_thickness',\r\n",
        " 'lh_precuneus_thickness',\r\n",
        " 'lh_rostralmiddlefrontal_thickness',\r\n",
        " 'lh_superiorfrontal_thickness',\r\n",
        " 'lh_superiortemporal_thickness',\r\n",
        " 'lh_supramarginal_thickness',\r\n",
        " 'lh_temporalpole_thickness',\r\n",
        " 'lh_MeanThickness_thickness',\r\n",
        " 'rh_bankssts_thickness',\r\n",
        " 'rh_caudalmiddlefrontal_thickness',\r\n",
        " 'rh_entorhinal_thickness',\r\n",
        " 'rh_fusiform_thickness',\r\n",
        " 'rh_parsorbitalis_thickness',\r\n",
        " 'rh_posteriorcingulate_thickness',\r\n",
        " 'rh_rostralmiddlefrontal_thickness',\r\n",
        " 'rh_superiorfrontal_thickness',\r\n",
        " 'rh_superiortemporal_thickness',\r\n",
        " 'rh_supramarginal_thickness',\r\n",
        " 'rh_frontalpole_thickness',\r\n",
        " 'rh_temporalpole_thickness',\r\n",
        " 'rh_MeanThickness_thickness',\r\n",
        " 'lh_medialorbitofrontal_meancurv',\r\n",
        " 'rh_entorhinal_meancurv',\r\n",
        " 'Frontal regions',\r\n",
        " 'Anterior/posterior cingulate regions',\r\n",
        " 'Lateral parietal regions',\r\n",
        " 'Lateral temporal regions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37WrZVSH1GZr"
      },
      "source": [
        "df_anova = data.loc[:,colname]\r\n",
        "df_anova[\"y\"] = data.iloc[:,4]\r\n",
        "df_anova = df_anova.dropna()\r\n",
        "df_anova.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-FPkkQf7hge"
      },
      "source": [
        "df_anova.y.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPKI2J1R3JbB"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\r\n",
        "X = df_anova.iloc[:,:-1]\r\n",
        "y = df_anova.iloc[:,-1]\r\n",
        "\r\n",
        "from scipy.stats import rankdata\r\n",
        "\r\n",
        "anova_col_see = pd.DataFrame(index=colname)\r\n",
        "#anova_col_see.sort_values(by=\"importance\", ascending=False)\r\n",
        "\r\n",
        "def randomforest_anova(datax,datay,df,n=30):\r\n",
        "  X= datax\r\n",
        "  y = datay\r\n",
        "  score_list = []\r\n",
        "  \r\n",
        "  for i in range(n):\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\r\n",
        "    clf = RandomForestClassifier()\r\n",
        "    clf.fit(X_train, y_train)\r\n",
        "    score = clf.score(X_test,y_test)\r\n",
        "    predicted = clf.predict(X_test)\r\n",
        "    score = clf.score(X_test,y_test)\r\n",
        "    print(score)\r\n",
        "    print('\\nClassification Report\\n')\r\n",
        "    print(classification_report(y_test, predicted))\r\n",
        "    plot_confusion_matrix(clf, X_test, y_test)  \r\n",
        "    plt.show() \r\n",
        "    score_list.append(score)\r\n",
        "    importance = clf.feature_importances_\r\n",
        "    df[i] = rankdata(importance)\r\n",
        "  return df,score_list\r\n",
        "\r\n",
        "df,scorelist = randomforest_anova(X,y,anova_col_see)\r\n",
        "anova_rank = pd.DataFrame(index=colname)\r\n",
        "rank_sum = df.sum(axis=1)\r\n",
        "anova_rank[\"sum\"] = rank_sum\r\n",
        "anova_rank[\"rank\"] = rankdata(rank_sum)\r\n",
        "\r\n",
        "mat_mul = np.matmul(df.to_numpy(),scorelist)\r\n",
        "anova_rank[\"weighted importance\"] = mat_mul\r\n",
        "anova_rank[\"weighted importace rank\"] = rankdata(mat_mul)\r\n",
        "anova_rank.sort_values(by=\"weighted importace rank\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnBDgAf5XDO"
      },
      "source": [
        "### anova - smote - random forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XffnfJRz6gyr"
      },
      "source": [
        "X = df_anova.iloc[:,:-1]\r\n",
        "y = df_anova.iloc[:,-1]\r\n",
        "\r\n",
        "def randomforest_anova_smote(datax,datay,df,n=30):\r\n",
        "  X = datax\r\n",
        "  y = datay\r\n",
        "  score_list = []\r\n",
        "  \r\n",
        "  for i in range(n):\r\n",
        "    \r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,stratify=y)\r\n",
        "\r\n",
        "    # transform the dataset & k_neighboors = 4 한 이유는 젤 작은 클라스 갯수가 5라서 k가 6 이상이면 못씀\r\n",
        "    oversample = SMOTE(k_neighbors=1)\r\n",
        "    X_train, y_train = oversample.fit_resample(X_train, y_train)\r\n",
        "    X_train = pd.DataFrame(X_train,columns=colname)\r\n",
        "    # summarize distribution\r\n",
        "    counter = Counter(y_train)\r\n",
        "    for k,v in counter.items():\r\n",
        "      per = v / len(y) * 100\r\n",
        "      print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\r\n",
        "    # plot the distribution\r\n",
        "    plt.bar(counter.keys(), counter.values())\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "    clf = RandomForestClassifier()\r\n",
        "    clf.fit(X_train, y_train)\r\n",
        "    score = clf.score(X_test,y_test)\r\n",
        "    predicted = clf.predict(X_test)\r\n",
        "    score = clf.score(X_test,y_test)\r\n",
        "    print(score)\r\n",
        "    print('\\nClassification Report\\n')\r\n",
        "    print(classification_report(y_test, predicted))\r\n",
        "    plot_confusion_matrix(clf, X_test, y_test)  \r\n",
        "    plt.show() \r\n",
        "    score_list.append(score)\r\n",
        "    importance = clf.feature_importances_\r\n",
        "    df[i] = rankdata(importance)\r\n",
        "  return df,score_list\r\n",
        "\r\n",
        "anova_col_see_smote = pd.DataFrame(index=colname)\r\n",
        "df_smote,scorelist_smote = randomforest_anova_smote(X,y,anova_col_see_smote)\r\n",
        "\r\n",
        "anova_rank_smote = pd.DataFrame(index=colname)\r\n",
        "rank_sum = df_smote.sum(axis=1)\r\n",
        "anova_rank_smote[\"sum_smote\"] = rank_sum\r\n",
        "anova_rank_smote[\"rank_smote\"] = rankdata(rank_sum)\r\n",
        "\r\n",
        "mat_mul = np.matmul(df.to_numpy(),scorelist)\r\n",
        "anova_rank_smote[\"weighted importance_smote\"] = mat_mul\r\n",
        "anova_rank_smote[\"weighted importace rank_smote\"] = rankdata(mat_mul)\r\n",
        "anova_rank_smote.sort_values(by=\"weighted importace rank_smote\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_rFOIJW8RPl"
      },
      "source": [
        "np.mean(scorelist_smote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEuG5I9XBaRK"
      },
      "source": [
        "total_rank = pd.merge(anova_rank,anova_rank_smote,left_index=True,right_index=True,how=\"left\" )\r\n",
        "total_rank[\"weighted importace rank_smote\"] == total_rank[\"weighted importace rank\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVWoX_k8Ioij"
      },
      "source": [
        "total_rank.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J7RPUdC8ZCC"
      },
      "source": [
        "forplot = total_rank[[\"weighted importance_smote\",\"weighted importance\"]].sort_values(by=\"weighted importance_smote\",ascending=False)\r\n",
        "forplot=forplot.drop( ['CERAD_J1','CERAD_J2','CERAD_J3','CERAD_J4','CERAD_J6','CERAD_J7','CERAD_J8','CERAD_J9A','CERAD_J9B','CERAD_J가1','CERAD_J가2', 'CDR'])\r\n",
        "forplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqSvGW1VDcgp"
      },
      "source": [
        "forplot.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQzx908ZtWRn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DqOJId6vud7"
      },
      "source": [
        "# frmi\r\n",
        "\r\n",
        "https://newkimchiman.tistory.com/27?category=588529\r\n",
        "\r\n",
        "fmri deep leaning methods\r\n",
        "https://www.frontiersin.org/articles/10.3389/fninf.2018.00023/full\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZif7XfVtSij"
      },
      "source": [
        "# 참고자료 : 이미지\r\n",
        "\r\n",
        "https://www.kaggle.com/polomarco/visualizatio-3d-nifti-dicom-matlab-nrrd-files"
      ]
    }
  ]
}